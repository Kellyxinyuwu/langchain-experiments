{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .venv (Python 3.14.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974d7c9-f978-4b70-b1ce-446d195edfa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a156db-62a4-4f05-9533-e3738dfa481d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage, ChatMessage\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6f812-a15b-4f1f-a9cb-a122cf4de127",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage, ChatMessage\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Load OpenAI API Token From the .env File\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2662470-d0d4-45fe-8b30-d604244cfbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kellywu/Desktop/langchain-experiments/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatOpenAI' from 'langchain.chat_models' (/Users/kellywu/Desktop/langchain-experiments/.venv/lib/python3.14/site-packages/langchain/chat_models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage, ChatMessage\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Load OpenAI API Token From the .env File\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ChatOpenAI' from 'langchain.chat_models' (/Users/kellywu/Desktop/langchain-experiments/.venv/lib/python3.14/site-packages/langchain/chat_models/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821735c6-b46b-446d-91c7-aeb2737a0995",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage, ChatMessage\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load OpenAI API Token From the .env File\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.schema'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51719c-79f3-4cb5-9104-1e2fee7854b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e09c66-46ac-47c8-b4e0-ea9e720f666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ca1e8-b584-4095-b83b-38f64839ac4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIRemovedInV1\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m openai.api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Ask ChatGPT a Question\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m completion = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo-0613\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhen\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms the next flight from Amsterdam to New York?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m output = completion.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-experiments/.venv/lib/python3.14/site-packages/openai/lib/_old_api.py:39\u001b[39m, in \u001b[36mAPIRemovedInV1Proxy.__call__\u001b[39m\u001b[34m(self, *_args, **_kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_args: Any, **_kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol=\u001b[38;5;28mself\u001b[39m._symbol)\n",
      "\u001b[31mAPIRemovedInV1\u001b[39m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Ask ChatGPT a Question\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"When's the next flight from Amsterdam to New York?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "print(output)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Use OpenAIâ€™s Function Calling Feature\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DUS\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. HAM\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "user_prompt = \"When's the next flight from Amsterdam to New York?\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    ")\n",
    "\n",
    "# It automatically fills the arguments with correct info based on the prompt\n",
    "# Note: the function does not exist yet\n",
    "\n",
    "output = completion.choices[0].message\n",
    "print(output)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Add a Function\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_flight_info(loc_origin, loc_destination):\n",
    "    \"\"\"Get flight information between two locations.\"\"\"\n",
    "\n",
    "    # Example output returned from an API or database\n",
    "    flight_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=2)),\n",
    "        \"airline\": \"KLM\",\n",
    "        \"flight\": \"KL643\",\n",
    "    }\n",
    "\n",
    "    return json.dumps(flight_info)\n",
    "\n",
    "\n",
    "# Use the LLM output to manually call the function\n",
    "# The json.loads function converts the string to a Python object\n",
    "\n",
    "origin = json.loads(output.function_call.arguments).get(\"loc_origin\")\n",
    "destination = json.loads(output.function_call.arguments).get(\"loc_destination\")\n",
    "params = json.loads(output.function_call.arguments)\n",
    "type(params)\n",
    "\n",
    "print(origin)\n",
    "print(destination)\n",
    "print(params)\n",
    "\n",
    "# Call the function with arguments\n",
    "\n",
    "chosen_function = eval(output.function_call.name)\n",
    "flight = chosen_function(**params)\n",
    "\n",
    "print(flight)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Add function result to the prompt for a final answer\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# The key is to add the function output back to the messages with role: function\n",
    "second_completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"function\", \"name\": output.function_call.name, \"content\": flight},\n",
    "    ],\n",
    "    functions=function_descriptions,\n",
    ")\n",
    "response = second_completion.choices[0].message.content\n",
    "print(response)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Include Multiple Functions\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Expand on function descriptions (3 functions)\n",
    "\n",
    "function_descriptions_multiple = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DUS\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. HAM\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"book_flight\",\n",
    "        \"description\": \"Book a flight based on flight information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DUS\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. HAM\",\n",
    "                },\n",
    "                \"datetime\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The date and time of the flight, e.g. 2023-01-01 01:01\",\n",
    "                },\n",
    "                \"airline\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The service airline, e.g. Lufthansa\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\", \"datetime\", \"airline\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"file_complaint\",\n",
    "        \"description\": \"File a complaint as a customer\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the user, e.g. John Doe\",\n",
    "                },\n",
    "                \"email\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The email address of the user, e.g. john@doe.com\",\n",
    "                },\n",
    "                \"text\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Description of issue\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"name\", \"email\", \"text\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "print(function_descriptions_multiple)\n",
    "\n",
    "\n",
    "def ask_and_reply(prompt):\n",
    "    \"\"\"Give LLM a given prompt and get an answer.\"\"\"\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        # add function calling\n",
    "        functions=function_descriptions_multiple,\n",
    "        function_call=\"auto\",  # specify the function call\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message\n",
    "    return output\n",
    "\n",
    "\n",
    "# Scenario 1: Check flight details\n",
    "\n",
    "user_prompt = \"When's the next flight from Amsterdam to New York?\"\n",
    "print(ask_and_reply(user_prompt))\n",
    "\n",
    "# Get info for the next prompt\n",
    "\n",
    "origin = json.loads(output.function_call.arguments).get(\"loc_origin\")\n",
    "destination = json.loads(output.function_call.arguments).get(\"loc_destination\")\n",
    "chosen_function = eval(output.function_call.name)\n",
    "flight = chosen_function(origin, destination)\n",
    "\n",
    "print(origin)\n",
    "print(destination)\n",
    "print(flight)\n",
    "\n",
    "flight_datetime = json.loads(flight).get(\"datetime\")\n",
    "flight_airline = json.loads(flight).get(\"airline\")\n",
    "\n",
    "print(flight_datetime)\n",
    "print(flight_airline)\n",
    "\n",
    "# Scenario 2: Book a new flight\n",
    "\n",
    "user_prompt = f\"I want to book a flight from {origin} to {destination} on {flight_datetime} with {flight_airline}\"\n",
    "print(ask_and_reply(user_prompt))\n",
    "\n",
    "# Scenario 3: File a complaint\n",
    "\n",
    "user_prompt = \"This is John Doe. I want to file a complaint about my missed flight. It was an unpleasant surprise. Email me a copy of the complaint to john@doe.com.\"\n",
    "print(ask_and_reply(user_prompt))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Make It Conversational With Langchain\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0)\n",
    "\n",
    "# Start a conversation with multiple requests\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "This is Jane Harris. I am an unhappy customer that wants you to do several things.\n",
    "First, I neeed to know when's the next flight from Amsterdam to New York.\n",
    "Please proceed to book that flight for me.\n",
    "Also, I want to file a complaint about my missed flight. It was an unpleasant surprise. \n",
    "Email me a copy of the complaint to jane@harris.com.\n",
    "Please give me a confirmation after all of these are done.\n",
    "\"\"\"\n",
    "\n",
    "# Returns the function of the first request (get_flight_info)\n",
    "\n",
    "first_response = llm.predict_messages(\n",
    "    [HumanMessage(content=user_prompt)], functions=function_descriptions_multiple\n",
    ")\n",
    "\n",
    "print(first_response)\n",
    "\n",
    "# Returns the function of the second request (book_flight)\n",
    "# It takes all the arguments from the prompt but not the returned information\n",
    "\n",
    "second_response = llm.predict_messages(\n",
    "    [\n",
    "        HumanMessage(content=user_prompt),\n",
    "        AIMessage(content=str(first_response.additional_kwargs)),\n",
    "        AIMessage(\n",
    "            role=\"function\",\n",
    "            additional_kwargs={\n",
    "                \"name\": first_response.additional_kwargs[\"function_call\"][\"name\"]\n",
    "            },\n",
    "            content=f\"Completed function {first_response.additional_kwargs['function_call']['name']}\",\n",
    "        ),\n",
    "    ],\n",
    "    functions=function_descriptions_multiple,\n",
    ")\n",
    "\n",
    "print(second_response)\n",
    "\n",
    "# Returns the function of the third request (file_complaint)\n",
    "\n",
    "third_response = llm.predict_messages(\n",
    "    [\n",
    "        HumanMessage(content=user_prompt),\n",
    "        AIMessage(content=str(first_response.additional_kwargs)),\n",
    "        AIMessage(content=str(second_response.additional_kwargs)),\n",
    "        AIMessage(\n",
    "            role=\"function\",\n",
    "            additional_kwargs={\n",
    "                \"name\": second_response.additional_kwargs[\"function_call\"][\"name\"]\n",
    "            },\n",
    "            content=f\"Completed function {second_response.additional_kwargs['function_call']['name']}\",\n",
    "        ),\n",
    "    ],\n",
    "    functions=function_descriptions_multiple,\n",
    ")\n",
    "\n",
    "print(third_response)\n",
    "\n",
    "# Conversational reply at the end of requests\n",
    "\n",
    "fourth_response = llm.predict_messages(\n",
    "    [\n",
    "        HumanMessage(content=user_prompt),\n",
    "        AIMessage(content=str(first_response.additional_kwargs)),\n",
    "        AIMessage(content=str(second_response.additional_kwargs)),\n",
    "        AIMessage(content=str(third_response.additional_kwargs)),\n",
    "        AIMessage(\n",
    "            role=\"function\",\n",
    "            additional_kwargs={\n",
    "                \"name\": third_response.additional_kwargs[\"function_call\"][\"name\"]\n",
    "            },\n",
    "            content=f\"Completed function {third_response.additional_kwargs['function_call']['name']}\",\n",
    "        ),\n",
    "    ],\n",
    "    functions=function_descriptions_multiple,\n",
    ")\n",
    "\n",
    "print(fourth_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154c6ed-e011-4c23-b546-5f3074077805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load OpenAI API Token From the .env File\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc08eb0-7daa-4ab9-874f-aee50bdca5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91944ec8-6693-4c6a-b03e-62ce9b73d6f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIRemovedInV1\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Ask ChatGPT a Question\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m completion = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo-0613\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhen\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms the next flight from Amsterdam to New York?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m output = completion.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-experiments/.venv/lib/python3.14/site-packages/openai/lib/_old_api.py:39\u001b[39m, in \u001b[36mAPIRemovedInV1Proxy.__call__\u001b[39m\u001b[34m(self, *_args, **_kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_args: Any, **_kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol=\u001b[38;5;28mself\u001b[39m._symbol)\n",
      "\u001b[31mAPIRemovedInV1\u001b[39m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Ask ChatGPT a Question\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"When's the next flight from Amsterdam to New York?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02603b-29fe-4cea-b011-5b11b9b801b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Ask ChatGPT a Question (new OpenAI SDK)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# reads OPENAI_API_KEY from your env\u001b[39;00m\n\u001b[32m      9\u001b[39m completion = client.chat.completions.create(\n\u001b[32m     10\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# or another available chat model\u001b[39;00m\n\u001b[32m     11\u001b[39m     messages=[\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     ],\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m output = completion.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-experiments/.venv/lib/python3.14/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Ask ChatGPT a Question (new OpenAI SDK)\n",
    "# --------------------------------------------------------------\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from your env\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or another available chat model\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"When's the next flight from Amsterdam to New York?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
